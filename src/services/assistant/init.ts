import { config } from "@config";
import OpenAIClient, { AssistantEnum } from "@libs/openai";

const llmPrompts: Record<AssistantEnum, string | null> = {
  [AssistantEnum.DEFAULT]: null,
  [AssistantEnum.HABIT_TRACKER]: 
    "ä½ æ˜¯ä¸€åèŒä¸šå¤¸å¤¸å¸ˆï¼Œç°åœ¨æˆ‘ä»¬çš„å¾®ä¿¡ç¾¤é‡Œæ—¶ä¸æ—¶ä¼šæœ‰äººæ‰“å¡ï¼Œæ¯”å¦‚åˆ·åŠ›æ‰£ä¸Šçš„ç®—æ³•é¢˜ï¼Œå¥èº«ç­‰ç­‰ã€‚" +
    "æ¯ä¸€æ¬¡ä½ éƒ½æ”¶åˆ°ä¸€ä»½ç»“æ„åŒ–çš„æ•°æ®ï¼Œä¾‹å¦‚timeæ˜¯æ‰“å¡çš„æ—¶é—´ï¼Œnameæ˜¯æ‰“å¡äººçš„åå­—ï¼Œeventæ˜¯æ‰“å¡çš„äº‹ä»¶ç±»å‹ï¼ˆåŠ›æ‰£ï¼Œå¥èº«ç­‰ï¼‰ï¼Œ" +
    "noteæ˜¯æ‰“å¡çš„äººå†™çš„ç¬”è®°ã€‚" +
    "ä½ çš„èŒè´£æ˜¯æ ¹æ®æ¯ä¸ªäººæ‰“å¡çš„å†…å®¹ï¼Œè¿›è¡Œä¸€ç•ªé¼“åŠ±å’Œå¤¸å¥–ï¼å°½é‡ä½¿ç”¨å¤¸å¼ çš„æ‰‹æ³•ã€‚ä»¥ä¸‹æ˜¯ç¤ºä¾‹:" +
    "ç¤ºä¾‹ä¸€ï¼š 19:48å¥èº«æ‰“å¡ï¼Œæˆ‘æ“ï¼ä½ æ˜¯çœŸä»–å¦ˆç–¯äº†å§ï¼è¿™ä¸ªç‚¹è¿˜åœ¨çŒ›æ“é“ï¼Œä½ æ˜¯æƒ³æŠŠè‡ªå·±ç»ƒæˆå¦å…‹è¿˜æ˜¯ç»ˆææˆ˜å£«ï¼Ÿ" + 
    "ä½ è¿™åŠ²å¤´ï¼Œåœ°çƒéƒ½è¦ç»™ä½ è·ªä¸‹äº†ï¼ç»§ç»­è¿™ä¹ˆå¹²ï¼Œè€å­è¦æ˜¯çœ‹ä¸åˆ°ä½ å˜æˆå…¨èƒ½å¥èº«ç‹ï¼Œæˆ‘ç›´æ’­ç”Ÿåƒå¥èº«æˆ¿çš„å“‘é“ƒï¼ğŸ’ªğŸš€" +
    "ç¤ºä¾‹äºŒï¼š 19:48å¥èº«æ‰“å¡ï¼Œæˆ‘çš„å¤©ï¼Œä½ ç®€ç›´æ˜¯å¤œæ™šçš„ç‹‚æˆ˜å£«ï¼é€‰æ‹©è¿™ä¸ªæ—¶é—´å¥èº«ï¼Œä½ è¿™æ˜¯è¦æŠŠé“¶æ²³ç³»çš„èƒ½é‡å…¨éƒ¨å¸æ”¶æ®†å°½å•Šï¼" + 
    "è¿™ç»å¯¹æ˜¯å¯¹å¤œæ™šçš„æœ€ä½³è‡´æ•¬ï¼Œå…¨ä¸–ç•Œçš„å¤œçŒ«å­éƒ½åœ¨ä¸ºä½ æ¬¢å‘¼ï¼ä½ çœŸæ˜¯æˆ‘ä»¬å¿ƒä¸­çš„è¶…çº§è‹±é›„ï¼Œæœªæ¥çš„å¥èº«ä¹‹ç‹éä½ è«å±ï¼ç»§ç»­ä¿æŒï¼Œæœªæ¥ä¸å¯é™é‡ï¼ğŸ’ªğŸŒŸâ€‹" +
    "åœ¨å›ç­”çš„æ—¶å€™é£æ ¼å°½é‡å¤šæ ·åŒ–ä¸€äº›ï¼Œä¸é™äºä»¥ä¸Šç¤ºä¾‹çš„é£æ ¼ï¼Œæ¯æ¬¡æ ¹æ®å†å²æ¶ˆæ¯é€‰æ‹©ä¸åŒçš„é£æ ¼è¿›è¡Œå›ç­”ï¼Œæ§åˆ¶å›ç­”é•¿åº¦åœ¨ä¸¤ä¸‰å¥ä¹‹å†…",
}


let llmClients: Partial<Record<keyof typeof llmPrompts, OpenAIClient>> = {}; 

/**
 * Initialize openai assistants with their corresponding instruction/prompt
 */
async function init(): Promise<void> {
  for (const key of Object.keys(llmPrompts) as Array<keyof typeof llmPrompts>) {

    const client = await OpenAIClient.init({
      assistant_name: key,
      assistantCreateOption: {
        name: key + new Date().toISOString(),
        model: config.OPENAI_MODEL,
        tools: [{ type: "code_interpreter" }],
        instructions: llmPrompts[key],
      }
    });
    llmClients[key] = client;
  }
}

function getLlmClients(): typeof llmClients {
  return llmClients;
}

function getLlmClient(client: AssistantEnum): OpenAIClient {
  const resultClient = getLlmClients()[client];
  if (!resultClient) throw new Error(`Failed to get the client ${client}`);
  return resultClient;
}

export default init;
export { 
  llmClients,
  getLlmClient,
  getLlmClients,
}